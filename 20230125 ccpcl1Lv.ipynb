{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44cd6896",
   "metadata": {},
   "source": [
    "Eugene's Script for scraping the first level of a property website getting the links to further scrape the property details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3bdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4894cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import re\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb291ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping with MS Edge\n",
    "\n",
    "desired_cap = {\n",
    "    \"os\" : \"OS X\",\n",
    "    \"os_version\" : \"Ventura\",\n",
    "    \"browser\" : \"Edge\",\n",
    "    \"browser_version\" : \"109.0.1518.70\",\n",
    "    \"browserstack.local\" : \"false\",\n",
    "    \"browserstack.selenium_version\" : \"3.141.0\"\n",
    "}\n",
    "\n",
    "# store an edge driver in the same folder you store this script\n",
    "browser = webdriver.Edge(executable_path='/Users/eugene/projects/address_parser/msedgedriver', capabilities=desired_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc559857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the target website for scraping\n",
    "init_url = 'http://cppcl.property.hk/tran_prop.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f65e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a function for fetching the links with specific property details for second layer scraping\n",
    "def transaction_details_pattern(uid: Tuple[str, str]) -> str:\n",
    "    return f\"http://cppcl.property.hk/tran_prop_detail.php?ref={uid[0]}&year={uid[1]}\"\n",
    "\n",
    "# create a function for fetching the links with specific property details for second layer scraping\n",
    "def create_address_model(data_tuple) -> dict:\n",
    "    return {\n",
    "        'id': data_tuple[0],\n",
    "        'source': data_tuple[1],\n",
    "        'chinese': {\n",
    "            'raw': None,\n",
    "            'address': data_tuple[2],\n",
    "            'floor': data_tuple[3],\n",
    "            'flat': data_tuple[4],\n",
    "        },\n",
    "        'english': {\n",
    "            'raw': None,\n",
    "            'address': None,\n",
    "            'floor': None,\n",
    "            'flat': None,\n",
    "        },\n",
    "        'data': {\n",
    "            'registration_number': None,\n",
    "            'registration_date': None,\n",
    "            'docs_date': None,\n",
    "            'gross_floor_area': data_tuple[5],\n",
    "            'saleable_floor_area': None,\n",
    "            'price(million)': data_tuple[6],\n",
    "            'price_per_feet_gross': data_tuple[7],\n",
    "            'price_per_feet_saleable': None,\n",
    "            'district': None,\n",
    "            'usage': None,\n",
    "            'occupation_permit': None,\n",
    "            'lease_term': None,\n",
    "            'renewable_term': None,\n",
    "            'facing': None,\n",
    "            'layout': None,\n",
    "            'seller': None,\n",
    "            'buyer': None,\n",
    "            'remark': None,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f26e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering the XPATHs for the target information we want\n",
    "# they will be put in the lower block for the browser.find_elements() function\n",
    "xpath_address = '/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[3]/tbody//td[3]'\n",
    "xpath_floor = '/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[3]/tbody//td[4]'\n",
    "xpath_flat = '/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[3]/tbody//td[5]'\n",
    "xpath_gross_area = '/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[3]/tbody//td[6]'\n",
    "xpath_price = '/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[3]/tbody//td[7]'\n",
    "xpath_price_per_feet = '/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[3]/tbody//td[8]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6af938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blank data listing for storing the scraped data\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407dd02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fetching info online with the XPATH\n",
    "# info of a single property is wrapped in \"data_tuple\" in the format of \"create_address_model\" dictionary above, the data_tuples are dictionaries\n",
    "# the data_tuples are stored in the data list above, so the data list is a list of dictionaries\n",
    "browser.get(init_url)\n",
    "for j in range(1, 7):\n",
    "    browser.find_elements_by_xpath(f'/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[1]/tbody[1]/tr[2]/td[4]/select/option[{j}]')[0].click()\n",
    "    browser.find_elements_by_xpath('/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[1]/tbody[1]/tr[2]/td[8]/input[1]')[0].click()\n",
    "    browser.find_elements_by_xpath(\"//*[contains(text(), '尾頁')]\")[0].click()\n",
    "    max_page = max(re.findall(\"\\d+\", browser.find_element(By.CLASS_NAME, \"stdPrevNext\").text))\n",
    "    for i in range(1, int(max_page) + 1):\n",
    "        browser.execute_script(f'javascript:findForm_submit(\"page\",{i})')\n",
    "        uids_tuple = list(map(lambda extract: re.findall(\"open_tran_prop_detail\\(\\\"([a-zA-Z0-9]+)\\\"\\,\\\"([0-9]+)\", extract)[0], \n",
    "                                            list(map(lambda xpath: xpath.get_attribute(\"onclick\"), \n",
    "                                                        browser.find_elements_by_xpath('/html/body/table/tbody/tr[2]/td/table/tbody/tr[3]/td/form/table[3]/tbody//td[9]/a')))))\n",
    "        uids = list(map(lambda x: f\"{x[0]}{x[1]}\", uids_tuple))\n",
    "        urls = list(map(transaction_details_pattern, uids_tuple))\n",
    "        address = list(map(lambda x: x.text, browser.find_elements_by_xpath(xpath_address)[1::]))\n",
    "        floor = list(map(lambda x: x.text, browser.find_elements_by_xpath(xpath_floor)[1::]))\n",
    "        flat = list(map(lambda x: x.text, browser.find_elements_by_xpath(xpath_flat)[1::]))\n",
    "        gross_area = list(map(lambda x: x.text, browser.find_elements_by_xpath(xpath_gross_area)[1::]))\n",
    "        price = list(map(lambda x: x.text, browser.find_elements_by_xpath(xpath_price)[1::]))\n",
    "        price_per_feet = list(map(lambda x: x.text, browser.find_elements_by_xpath(xpath_price_per_feet)[1::]))\n",
    "\n",
    "        data_tuple = list(zip(uids, urls, address, floor, flat, gross_area, price, price_per_feet))\n",
    "        data.extend(list(map(create_address_model, data_tuple)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many properties were scraped\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into pickle\n",
    "import pickle\n",
    "with open('ccpcl.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the pickle file and check\n",
    "import pickle\n",
    "\n",
    "objects = []\n",
    "with (open(\"ccpcl.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "95b771fd535f56a4ab1b497812d11b204c2ee3b405646ad4bae3a6256787e070"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
